"""
RAG (Retrieval-Augmented Generation) ì‹œìŠ¤í…œ
Milvus ë²¡í„° ìŠ¤í† ì–´ì™€ Watsonx LLMì„ í†µí•©í•œ ì™„ì „í•œ RAG ì‹œìŠ¤í…œ
"""
import os
from typing import List, Dict, Any, Optional, Tuple
from dotenv import load_dotenv

from langchain_core.documents import Document
from langchain_core.retrievers import BaseRetriever
from langchain_core.callbacks import CallbackManagerForRetrieverRun

from .embedding import WatsonxEmbeddingManager
from .milvus_manager import MilvusVectorStoreManager

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


class InstanaRAGSystem:
    """Instana ë¬¸ì„œ ê¸°ë°˜ RAG ì‹œìŠ¤í…œ"""
    
    def __init__(self, 
                 collection_name: str = "instana_docs",
                 top_k: int = 10,
                 similarity_threshold: float = 0.4):
        """
        RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        
        Args:
            collection_name: Milvus ì»¬ë ‰ì…˜ ì´ë¦„
            top_k: ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜
            similarity_threshold: ìœ ì‚¬ë„ ì„ê³„ê°’
        """
        self.collection_name = collection_name
        self.top_k = top_k
        self.similarity_threshold = similarity_threshold
        
        # ì„ë² ë”© ë§¤ë‹ˆì € ì´ˆê¸°í™”
        self.embedding_manager = WatsonxEmbeddingManager(
            model_id="ibm/granite-embedding-107m-multilingual"
        )
        
        # ë²¡í„° ìŠ¤í† ì–´ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        self.vectorstore_manager = MilvusVectorStoreManager(
            embeddings=self.embedding_manager.get_embeddings(),
            collection_name=collection_name
        )
        
        print(f"RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ:")
        print(f"  - ì»¬ë ‰ì…˜: {collection_name}")
        print(f"  - ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜: {top_k}")
        print(f"  - ìœ ì‚¬ë„ ì„ê³„ê°’: {similarity_threshold}")
    
    def search_documents(self, query: str) -> List[Document]:
        """
        ì¿¼ë¦¬ì— ëŒ€í•œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            
        Returns:
            ê´€ë ¨ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        """
        try:
            # ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰ (ë” ë§ì€ ê²°ê³¼ë¥¼ ìœ„í•´ k ê°’ì„ ì¦ê°€)
            results = self.vectorstore_manager.similarity_search(query, k=10)
            
            print(f"'{query}' ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ ë¬¸ì„œ ë°œê²¬")
            return results
            
        except Exception as e:
            print(f"ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def search_with_scores(self, query: str) -> List[Tuple[Document, float]]:
        """
        ì ìˆ˜ì™€ í•¨ê»˜ ë¬¸ì„œ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            
        Returns:
            (ë¬¸ì„œ, ì ìˆ˜) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
        """
        try:
            results = self.vectorstore_manager.similarity_search_with_score(query, k=self.top_k)
            
            print(f"'{query}' ì›ë³¸ ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ ë¬¸ì„œ")
            
            # ìœ ì‚¬ë„ ì„ê³„ê°’ í•„í„°ë§ (ì„ê³„ê°’ì„ ë‚®ì¶°ì„œ ë” ë§ì€ ê²°ê³¼ í¬í•¨)
            filtered_results = [
                (doc, score) for doc, score in results 
                if score >= 0.3  # ì„ê³„ê°’ì„ 0.3ìœ¼ë¡œ ë‚®ì¶¤
            ]
            
            print(f"'{query}' í•„í„°ë§ í›„ ê²°ê³¼: {len(filtered_results)}ê°œ ë¬¸ì„œ (ì„ê³„ê°’: 0.3)")
            return filtered_results
            
        except Exception as e:
            print(f"ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def get_context(self, query: str) -> str:
        """
        ì¿¼ë¦¬ì— ëŒ€í•œ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            
        Returns:
            ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´
        """
        try:
            # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
            documents = self.search_documents(query)
            
            if not documents:
                return "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context_parts = []
            for i, doc in enumerate(documents, 1):
                # ë¬¸ì„œ ë‚´ìš© ìš”ì•½ (ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ë‚´ê¸°)
                content = doc.page_content
                if len(content) > 500:
                    content = content[:500] + "..."
                
                # ë©”íƒ€ë°ì´í„°ì—ì„œ í˜ì´ì§€ ì •ë³´ ì¶”ì¶œ
                page_info = ""
                if 'page' in doc.metadata:
                    page_info = f" (í˜ì´ì§€ {doc.metadata['page']})"
                
                context_parts.append(f"[ë¬¸ì„œ {i}{page_info}]\n{content}")
            
            context = "\n\n".join(context_parts)
            
            print(f"ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ: {len(context)}ì")
            return context
            
        except Exception as e:
            print(f"ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return "ì»¨í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    def get_detailed_context(self, query: str) -> Dict[str, Any]:
        """
        ìƒì„¸í•œ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ë°˜í™˜
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            
        Returns:
            ìƒì„¸ ì»¨í…ìŠ¤íŠ¸ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # ì ìˆ˜ì™€ í•¨ê»˜ ê²€ìƒ‰
            results = self.search_with_scores(query)
            
            if not results:
                return {
                    "context": "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "sources": [],
                    "total_documents": 0,
                    "average_score": 0.0
                }
            
            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context_parts = []
            sources = []
            total_score = 0.0
            
            for i, (doc, score) in enumerate(results, 1):
                # ë¬¸ì„œ ë‚´ìš©
                content = doc.page_content
                if len(content) > 400:
                    content = content[:400] + "..."
                
                # ì†ŒìŠ¤ ì •ë³´
                source_info = {
                    "document_id": i,
                    "page": doc.metadata.get('page', 'N/A'),
                    "chunk_id": doc.metadata.get('chunk_id', 'N/A'),
                    "score": round(score, 4),
                    "content_preview": content[:100] + "..." if len(content) > 100 else content
                }
                sources.append(source_info)
                
                # ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€
                page_info = f" (í˜ì´ì§€ {doc.metadata.get('page', 'N/A')}, ì ìˆ˜: {score:.3f})"
                context_parts.append(f"[ë¬¸ì„œ {i}{page_info}]\n{content}")
                
                total_score += score
            
            context = "\n\n".join(context_parts)
            average_score = total_score / len(results)
            
            return {
                "context": context,
                "sources": sources,
                "total_documents": len(results),
                "average_score": round(average_score, 4)
            }
            
        except Exception as e:
            print(f"ìƒì„¸ ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                "context": "ì»¨í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "sources": [],
                "total_documents": 0,
                "average_score": 0.0
            }
    
    def test_rag_system(self) -> bool:
        """
        RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
        
        Returns:
            í…ŒìŠ¤íŠ¸ ì„±ê³µ ì—¬ë¶€
        """
        try:
            print("ğŸ” RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
            
            # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
            test_queries = [
                "Instanaë€ ë¬´ì—‡ì¸ê°€ìš”?",
                "ì• í”Œë¦¬ì¼€ì´ì…˜ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§",
                "IBMì˜ ê´€ì°° ê°€ëŠ¥ì„± ì†”ë£¨ì…˜",
                "ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ëª¨ë‹ˆí„°ë§"
            ]
            
            for query in test_queries:
                print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: '{query}'")
                
                # ë¬¸ì„œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
                documents = self.search_documents(query)
                if not documents:
                    print(f"âŒ '{query}' ê²€ìƒ‰ ì‹¤íŒ¨")
                    return False
                
                print(f"âœ… {len(documents)}ê°œ ë¬¸ì„œ ê²€ìƒ‰ ì„±ê³µ")
                
                # ì»¨í…ìŠ¤íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸
                context = self.get_context(query)
                if len(context) < 50:
                    print(f"âŒ '{query}' ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨")
                    return False
                
                print(f"âœ… ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì„±ê³µ ({len(context)}ì)")
            
            print("\nğŸ‰ RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
            return True
            
        except Exception as e:
            print(f"âŒ RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False


class InstanaRetriever(BaseRetriever):
    """LangChain í˜¸í™˜ ê²€ìƒ‰ê¸°"""
    
    def __init__(self, rag_system: InstanaRAGSystem):
        super().__init__()
        self.rag_system = rag_system
    
    def _get_relevant_documents(
        self, 
        query: str, 
        *, 
        run_manager: CallbackManagerForRetrieverRun
    ) -> List[Document]:
        """ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰"""
        return self.rag_system.search_documents(query)


def create_rag_system(collection_name: str = "instana_docs") -> InstanaRAGSystem:
    """
    RAG ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    
    Args:
        collection_name: Milvus ì»¬ë ‰ì…˜ ì´ë¦„
        
    Returns:
        InstanaRAGSystem ì¸ìŠ¤í„´ìŠ¤
    """
    return InstanaRAGSystem(collection_name=collection_name)


def create_retriever(rag_system: InstanaRAGSystem) -> InstanaRetriever:
    """
    LangChain í˜¸í™˜ ê²€ìƒ‰ê¸° ìƒì„±
    
    Args:
        rag_system: RAG ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤
        
    Returns:
        InstanaRetriever ì¸ìŠ¤í„´ìŠ¤
    """
    return InstanaRetriever(rag_system)
