"""
AskStan - Streamlit ì• í”Œë¦¬ì¼€ì´ì…˜
"""
import os
import io
import qrcode
import re
from dotenv import load_dotenv

import streamlit as st
from core.llm import build_streaming_chain, get_rag_context

# =============================================================================
# ì„¤ì • ë° ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# =============================================================================
load_dotenv()

st.set_page_config(
    page_title="AskStan", 
    page_icon="data/instana-logo.png", 
    layout="centered"
)

st.markdown("""
<style>
.stButton>button {
    background-color: #006699; /* ë…¹ìƒ‰ */
    color: white;
    border: 2px solid #006699;
}
.stButton>button:hover {
    background-color: #006699;
    color: white;
    border: 2px solid #006699;
}
</style>
""", unsafe_allow_html=True)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "history" not in st.session_state:
    st.session_state.history = []  # [{"role": "user"|"assistant", "content": str}]

if "turns" not in st.session_state:
    st.session_state.turns = 0

if "qr_shown" not in st.session_state:
    st.session_state.qr_shown = False

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
CHAT_TURNS_LIMIT = int(os.getenv("CHAT_TURNS_LIMIT"))
QR_TEXT = os.getenv("QR_TEXT")

# ìŠ¤íŠ¸ë¦¬ë° ì²´ì¸ ì´ˆê¸°í™” (RAG í†µí•©)
if "streaming_chain" not in st.session_state:
    st.session_state.streaming_chain = build_streaming_chain()


def qr_image_bytes(data: str) -> bytes:
    """QR ì½”ë“œ ì´ë¯¸ì§€ë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜"""
    img = qrcode.make(data)
    buf = io.BytesIO()
    img.save(buf, format="PNG")
    return buf.getvalue()


@st.dialog("ë°ëª¨ ì°¸ì—¬ ì™„ë£Œ!ğŸ‰", width="small", dismissible=False)
def show_qr_dialog():
    """ëŒ€í™” í•œë„ ë„ë‹¬ ì‹œ QR ì½”ë“œë¥¼ íŒì—…ìœ¼ë¡œ í‘œì‹œ"""
    st.markdown("ì•„ë˜ QR ì½”ë“œë¥¼ ìŠ¤ë§ˆíŠ¸í°ì„ í†µí•´ ìŠ¤ìº”í•˜ì—¬ ì„¤ë¬¸ì— ì°¸ì—¬í•´ì£¼ì„¸ìš”!")
    st.markdown("ì„¤ë¬¸ ì™„ë£Œ ì‹œ, IBM Quantum í‹°ì…”ì¸ ë¥¼ ë“œë¦½ë‹ˆë‹¤. ğŸ¤—")
    
    # QR ì½”ë“œ ì´ë¯¸ì§€ í‘œì‹œ
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        st.image(qr_image_bytes(QR_TEXT), width=300)
    
    st.markdown("---")
    
    # ëŒ€í™” ë‹¤ì‹œ ì‹œì‘í•˜ê¸° ë²„íŠ¼
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        if st.button("ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ê¸°", type="primary", use_container_width=True):
            # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
            st.session_state.history = []
            st.session_state.turns = 0
            st.session_state.qr_shown = False
            st.rerun()




def stream_response_generator(user_input: str, history: list):
    """RAG ê¸°ë°˜ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ìœ„í•œ ì œë„ˆë ˆì´í„° í•¨ìˆ˜"""
    try:
        # LangChain í˜•ì‹ìœ¼ë¡œ íˆìŠ¤í† ë¦¬ ë³€í™˜
        lc_history = []
        for h in history[:-1]:  # í˜„ì¬ ì‚¬ìš©ì ì…ë ¥ ì œì™¸
            if h["role"] == "user":
                lc_history.append(("human", h["content"]))
            else:
                lc_history.append(("ai", h["content"]))

        # RAG í†µí•© ì²´ì¸ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
        for chunk in st.session_state.streaming_chain.stream({
            "input": user_input, 
            "history": lc_history
        }):
            yield chunk
                    
    except Exception as e:
        yield f"RAG LLM í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"


# =============================================================================
# UI ë Œë”ë§
# =============================================================================
# í—¤ë” ì„¹ì…˜
col1, col2 = st.columns([1, 7])
with col1:
    st.image("data/instana-logo.png", width=80)
with col2:
    st.title("AskStan")

st.caption("IBMì˜ Instanaì— ëŒ€í•´ ê¶ê¸ˆí•œ ì§ˆë¬¸ì„ ë¬¼ì–´ë³´ì„¸ìš”!")

# ëŒ€í™” íˆìŠ¤í† ë¦¬ ë Œë”ë§
for msg in st.session_state.history:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ëŒ€í™” í•œë„ ë„ë‹¬ ì‹œ ì„¤ë¬¸ ë²„íŠ¼ í‘œì‹œ
if st.session_state.turns >= CHAT_TURNS_LIMIT and not st.session_state.qr_shown:
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        if st.button("ğŸ ì„¤ë¬¸ í›„ ì„ ë¬¼ë°›ê¸°", type="primary", use_container_width=True):
            show_qr_dialog()
            st.session_state.qr_shown = True

# =============================================================================
# ì±„íŒ… ì…ë ¥ ë° ì²˜ë¦¬
# =============================================================================
input_disabled = st.session_state.turns >= CHAT_TURNS_LIMIT
user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...", disabled=input_disabled)

if user_input is not None and not input_disabled:
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€ ë° í‘œì‹œ
    st.session_state.history.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # RAG ê¸°ë°˜ ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        # RAG ëª¨ë“œ: ë¬¸ì„œ ê²€ìƒ‰ í›„ ì‘ë‹µ ìƒì„±
        with st.spinner("ğŸ“š ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            # RAG ì»¨í…ìŠ¤íŠ¸ ë¯¸ë¦¬ ìƒì„± (ì‚¬ìš©ìì—ê²Œ í”¼ë“œë°± ì œê³µ)
            rag_context = get_rag_context(user_input)
            
        
        # RAG ê¸°ë°˜ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
        response_generator = stream_response_generator(user_input, st.session_state.history)
        full_response = st.write_stream(response_generator)

    # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€ ë° í„´ ì¹´ìš´íŠ¸ ì¦ê°€
    st.session_state.history.append({"role": "assistant", "content": full_response})
    st.session_state.turns += 1

    # ëŒ€í™” í•œë„ ë„ë‹¬ ì‹œ í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ë²„íŠ¼ í‘œì‹œ
    if st.session_state.turns >= CHAT_TURNS_LIMIT:
        st.rerun()